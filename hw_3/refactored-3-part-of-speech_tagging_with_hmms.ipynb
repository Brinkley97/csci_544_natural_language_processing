{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3-Part-of-Speech Tagging with HMMs + Decoding Techniques (Greedy and Viterbi)\n",
    "\n",
    "- Detravious Jamari Brinkley\n",
    "- CSCI-544: Applied Natural Language Processing\n",
    "- python version: 3.11.4\n",
    "\n",
    "---\n",
    "\n",
    "1. Part-of-Speech (POS) Tagging [a type of sequence labelling task where of a given word, assign the part of speech]\n",
    "2. HMMs (Hidden Markov Model) [a generative-based model that's used for POS Tagging]\n",
    "    1. Generative-based [provides the probabilities for all possible combinations of values of variables in the set using the joint distribution]\n",
    "    2. With POS Tagging: Given a sequence of observations (sentences), the task is to infer the most likely sequence of hidden states (POS Tags) that could have generated the observed data.\n",
    "3. **Decoding Techniques:**\n",
    "    1. Greedy [find the optimal (OPT) solution at each step]\n",
    "    2. Viterbi [make use of dynammic programming to find the OPT solution with backtracking while searching the entire search space]\n",
    "4. **Notes of the data and given files:**\n",
    "    - Dataset: Wall Street Journal section of the Penn Treebank\n",
    "    - Folder named `data` with the following files:\n",
    "        1. `train`, sentences *with* human-annotated POS Tags\n",
    "        2. `dev`, sentences *with* human-annotated POS Tags\n",
    "        3. `test`, sentences *without* POS Tags, thus predict the POS Tags\n",
    "    - Format: Blank like at the end of each sentence. Each line contains 3 items separated by the `\\t`, the tab symbol. These three items are\n",
    "        1. Index of the word in the sentence\n",
    "        2. Word type\n",
    "        3. POS Tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Update Data\n",
    "- [x] Find a way to separate sentences when loading the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, file_name: str, config_index: bool = True):\n",
    "    \n",
    "    if config_index == True:\n",
    "        file =  file_path + file_name\n",
    "        open_df = pd.read_table(file, sep = \"\\t\", names=['Index', 'Word', 'POS Tag'], skip_blank_lines=False)\n",
    "        # open_df = open_df.set_index('1')\n",
    "        \n",
    "    return open_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_columns(df: pd.DataFrame, new_columns_name: list, about: str) -> pd.DataFrame:  \n",
    "    \"\"\"Update the columns of the dataframe if first column is data needed\"\"\"  \n",
    "\n",
    "    original_index = df.index.copy()\n",
    "    N_columns = len(df.columns.to_list())\n",
    "\n",
    "\n",
    "    print(about, \"has 3 columns\")\n",
    "    dummy_row = pd.DataFrame([['0.0', ' ', 'dummy']], columns=df.columns)\n",
    "    # word = df.columns.to_list()[1]\n",
    "    # pos_tag = df.columns.to_list()[2]\n",
    "    # new_row = pd.DataFrame([['0.0', word, pos_tag]], columns=df.columns)\n",
    "    df = pd.concat([dummy_row, df], ignore_index=True)\n",
    "    df.columns = new_columns_name\n",
    "    df.fillna(\"dummy\", inplace=True)\n",
    "\n",
    "    print(\"Update complete\\n\") \n",
    "    # new_index = original_index.append(pd.Index(range(len(df) - len(original_index))))\n",
    "    # df = df.set_index(new_index)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950307</th>\n",
       "      <td>22.0</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950308</th>\n",
       "      <td>23.0</td>\n",
       "      <td>San</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950309</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>25.0</td>\n",
       "      <td>instead</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950311</th>\n",
       "      <td>26.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index       Word POS Tag\n",
       "0         1.0     Pierre     NNP\n",
       "1         2.0     Vinken     NNP\n",
       "2         3.0          ,       ,\n",
       "3         4.0         61      CD\n",
       "4         5.0      years     NNS\n",
       "...       ...        ...     ...\n",
       "950307   22.0         to      TO\n",
       "950308   23.0        San     NNP\n",
       "950309   24.0  Francisco     NNP\n",
       "950310   25.0    instead      RB\n",
       "950311   26.0          .       .\n",
       "\n",
       "[950312 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_data('data/', 'train')\n",
    "dev_df = load_data('data/', 'dev')\n",
    "test_df = load_data('data/', 'test')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.',\n",
       "       nan, 'VBZ', 'VBG', 'CC', 'VBD', 'VBN', 'RB', 'TO', 'PRP', 'RBR',\n",
       "       'WDT', 'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP',\n",
       "       ':', 'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT',\n",
       "       'RBS', 'FW', 'UH', 'SYM', 'LS', '#'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_tags = train_df['POS Tag'].unique()\n",
    "all_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Influential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135110</th>\n",
       "      <td>26.0</td>\n",
       "      <td>them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135111</th>\n",
       "      <td>27.0</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135112</th>\n",
       "      <td>28.0</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135113</th>\n",
       "      <td>29.0</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135114</th>\n",
       "      <td>30.0</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index         Word\n",
       "0         1.0  Influential\n",
       "1         2.0      members\n",
       "2         3.0           of\n",
       "3         4.0          the\n",
       "4         5.0        House\n",
       "...       ...          ...\n",
       "135110   26.0         them\n",
       "135111   27.0         here\n",
       "135112   28.0         with\n",
       "135113   29.0           us\n",
       "135114   30.0            .\n",
       "\n",
       "[135115 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_test_df = test_df.drop(['POS Tag'], axis=1)\n",
    "updated_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 3 columns\n",
      "Update complete\n",
      "\n",
      "Dev data has 3 columns\n",
      "Update complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "two_columns_name = ['Index', 'Word', 'POS Tag']\n",
    "# one_columns_name = ['Index', 'Word', 'POS Tag']\n",
    "\n",
    "updated_train_df = update_df_columns(train_df, two_columns_name, \"Train data\")\n",
    "updated_dev_df = update_df_columns(dev_df, two_columns_name, \"Dev data\")\n",
    "# updated_test_df = update_df_columns(test_df, one_columns_name, \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Influential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>introduced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>legislation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>restrict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>savings-and-loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>bailout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>creating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>potential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>obstacle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index              Word\n",
       "0     1.0       Influential\n",
       "1     2.0           members\n",
       "2     3.0                of\n",
       "3     4.0               the\n",
       "4     5.0             House\n",
       "5     6.0              Ways\n",
       "6     7.0               and\n",
       "7     8.0             Means\n",
       "8     9.0         Committee\n",
       "9    10.0        introduced\n",
       "10   11.0       legislation\n",
       "11   12.0              that\n",
       "12   13.0             would\n",
       "13   14.0          restrict\n",
       "14   15.0               how\n",
       "15   16.0               the\n",
       "16   17.0               new\n",
       "17   18.0  savings-and-loan\n",
       "18   19.0           bailout\n",
       "19   20.0            agency\n",
       "20   21.0               can\n",
       "21   22.0             raise\n",
       "22   23.0           capital\n",
       "23   24.0                 ,\n",
       "24   25.0          creating\n",
       "25   26.0           another\n",
       "26   27.0         potential\n",
       "27   28.0          obstacle\n",
       "28   29.0                to\n",
       "29   30.0               the\n",
       "30   31.0        government\n",
       "31   32.0                's\n",
       "32   33.0              sale"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_test_df.head(33)\n",
    "# updated_train_df.tail(5)\n",
    "# updated_train_df\n",
    "\n",
    "# updated_train_df[updated_train_df['POS Tag'] == \"dummy\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of Tasks\n",
    "\n",
    "1. Vocabulary Creation\n",
    "2. Model Learning\n",
    "3. Greedy Decoding with HMM\n",
    "4. Viterbi Decoding with HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vocabulary Creation\n",
    "\n",
    "- **Problem:** Creating vocabulary to handle unkown words.\n",
    "    - **Solution:** Replace rare words wtih whose occurrences are less than a threshold (ie: 3) with a special token `< unk >`\n",
    "\n",
    "---\n",
    "\n",
    "1. [ ] Create a vocabulary using the training data in the file train\n",
    "2. [ ] Output the vocabulary into a txt file named `vocab.txt`\n",
    "    - [ ] See PDF on how to properly format vocabulary file\n",
    "3. [ ] Questions\n",
    "    1. [ ] What is the selected threshold for unknown words replacement?\n",
    "    2. [ ] What is the total size of your vocabulary?\n",
    "    3. [ ] What is the total occurrences of the special token `< unk >`after replacement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siddhant\n",
    "# shivam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n",
      ",           46476\n",
      "the         39533\n",
      "dummy       38234\n",
      ".           37452\n",
      "of          22104\n",
      "            ...  \n",
      "Birthday        1\n",
      "Happy           1\n",
      "Bertie          1\n",
      "crouched        1\n",
      "Huricane        1\n",
      "Name: count, Length: 43193, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "true_false_series = updated_train_df['Word'].value_counts()\n",
    "print(true_false_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(true_false_series)\n",
    "vocab_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_30689/3980822034.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_false_vocab_df['Word'] = ' <unk> '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>29443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "      <td>38234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>trafficking</td>\n",
       "      <td>13746</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>7.62</td>\n",
       "      <td>13747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>gut</td>\n",
       "      <td>13748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13749</th>\n",
       "      <td>17.3</td>\n",
       "      <td>13749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>seminar</td>\n",
       "      <td>13750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  index  count\n",
       "0            <unk>      0  29443\n",
       "1                ,      1  46476\n",
       "2              the      2  39533\n",
       "3            dummy      3  38234\n",
       "4                .      4  37452\n",
       "...            ...    ...    ...\n",
       "13746  trafficking  13746      4\n",
       "13747         7.62  13747      4\n",
       "13748          gut  13748      4\n",
       "13749         17.3  13749      4\n",
       "13750      seminar  13750      4\n",
       "\n",
       "[13751 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_false_series = vocab_df['count'] > 3\n",
    "\n",
    "updated_vocab_df = vocab_df.loc[true_false_series == True]\n",
    "updated_false_vocab_df = vocab_df.loc[true_false_series == False]\n",
    "updated_false_vocab_df['Word'] = ' <unk> '\n",
    "print()\n",
    "N_updated_false_vocab_df = len(updated_false_vocab_df)\n",
    "N_updated_false_vocab_df\n",
    "new_row = pd.DataFrame([['<unk>', N_updated_false_vocab_df]], columns=updated_vocab_df.columns)\n",
    "new_row\n",
    "df = pd.concat([new_row, updated_vocab_df], ignore_index=True)\n",
    "N_vocab = range(0, len(updated_vocab_df)+1)\n",
    "\n",
    "df['index'] = N_vocab\n",
    "\n",
    "df = df.reindex(columns=['Word', 'index', 'count'])\n",
    "df\n",
    "# df.to_csv('vocab.txt', header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>29443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "      <td>38234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>trafficking</td>\n",
       "      <td>13746</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>7.62</td>\n",
       "      <td>13747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>gut</td>\n",
       "      <td>13748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13749</th>\n",
       "      <td>17.3</td>\n",
       "      <td>13749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>seminar</td>\n",
       "      <td>13750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  index  count\n",
       "0            <unk>      0  29443\n",
       "1                ,      1  46476\n",
       "2              the      2  39533\n",
       "3            dummy      3  38234\n",
       "4                .      4  37452\n",
       "...            ...    ...    ...\n",
       "13746  trafficking  13746      4\n",
       "13747         7.62  13747      4\n",
       "13748          gut  13748      4\n",
       "13749         17.3  13749      4\n",
       "13750      seminar  13750      4\n",
       "\n",
       "[13751 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Learning\n",
    "\n",
    "- Learn an HMM from the training data\n",
    "- **HMM Parameters:**\n",
    "  <div style=\"text-align: center;\">\n",
    "\n",
    "    $\n",
    "    \\text{Transition Probability (} t \\text{)}: \\quad t(s' \\mid s) = \\frac{\\text{count}(s \\rightarrow s')}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "    $\n",
    "    \\text{Emission Probability (} e \\text{)}: \\quad e(x \\mid s) = \\frac{\\text{count}(s \\rightarrow x)}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "  </div>\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Learn a model using the training data in the file train\n",
    "2. [ ] Output the learned model into a model file in json format, named `hmm.json`. The model file should contains two dictionaries for the emission and transition parameters, respectively.\n",
    "    1. [ ] 1st dictionary: Named transition, contains items with pairs of (s, s′) as key and t(s′|s) as value. \n",
    "    2. [ ] 2nd dictionary: Named emission, contains items with pairs of (s, x) as key and e(x|s) as value.\n",
    "3. Question\n",
    "    1. [ ] How many transition and emission parameters in your HMM?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>old</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>join</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>board</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>nonexecutive</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>director</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Nov.</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>29</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index          Word POS Tag\n",
       "0     0.0                 dummy\n",
       "1     1.0        Pierre     NNP\n",
       "2     2.0        Vinken     NNP\n",
       "3     3.0             ,       ,\n",
       "4     4.0            61      CD\n",
       "5     5.0         years     NNS\n",
       "6     6.0           old      JJ\n",
       "7     7.0             ,       ,\n",
       "8     8.0          will      MD\n",
       "9     9.0          join      VB\n",
       "10   10.0           the      DT\n",
       "11   11.0         board      NN\n",
       "12   12.0            as      IN\n",
       "13   13.0             a      DT\n",
       "14   14.0  nonexecutive      JJ\n",
       "15   15.0      director      NN\n",
       "16   16.0          Nov.     NNP\n",
       "17   17.0            29      CD\n",
       "18   18.0             .       .\n",
       "19  dummy         dummy   dummy"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm(df):\n",
    "    transition_states = defaultdict(int)\n",
    "    emission_state_word = defaultdict(int)\n",
    "    N_state = defaultdict(int)\n",
    "    \n",
    "\n",
    "    df['Previous_POS Tag'] = df['POS Tag'].shift(1) # previous state for trnasition probabilities\n",
    "\n",
    "    # iterate through vocabulary\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "        emission_state_word[(row[\"POS Tag\"], row[\"Word\"])] += 1\n",
    "        # transition count + 1\n",
    "        if pd.notnull(row['Previous_POS Tag']):  # Check if it's not NaN\n",
    "            transition_states[(row[\"Previous_POS Tag\"], row['POS Tag'])] += 1\n",
    "\n",
    "        # increment tag when I see it\n",
    "        N_state[(row[\"POS Tag\"])] += 1\n",
    "\n",
    "    # print(emission_state_word)\n",
    "    # print(transition_states)\n",
    "    # print(N_state)\n",
    "\n",
    "    return emission_state_word, transition_states, N_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 950313/950313 [00:51<00:00, 18578.04it/s]\n"
     ]
    }
   ],
   "source": [
    "emissions, transitions, N_states = hmm(updated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_t_prob(transitions, N_states):    \n",
    "    # Calculate probabilities\n",
    "    transition_probs = {} # dictionary definition\n",
    "    for key,value in transitions.items(): # iterate through dicitionary \n",
    "\n",
    "        curr_state = key[0]\n",
    "        # print('current state: ', curr_state, \"\\nKey: \", key)\n",
    "        # print(\"Value of dictionary at the index: \", value,'\\nNumber of times this state has been the current state: ', N_states[curr_state])\n",
    "\n",
    "        # count(given s, find s') / given s\n",
    "        transition_probs[key] = value / N_states[curr_state]\n",
    "\n",
    "        # count(given s, find w) / given s\n",
    "        \n",
    "        # how many times you've seen the (s => s') = v / how many times you've seen the current state , s  \n",
    "        # break \n",
    "    # print(transition_probs)\n",
    "\n",
    "    return transition_probs\n",
    "\n",
    "# Calculate emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_probs = calculate_t_prob(transitions, N_states)\n",
    "# t_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dummy', 'NNP'), 0.19789104610393007),\n",
       " (('NNP', 'NNP'), 0.3782645420509543),\n",
       " (('NNP', ','), 0.13846908958086018)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t_probs.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dummy', ' '), 1), (('NNP', 'Pierre'), 6), (('NNP', 'Vinken'), 2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(emissions.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_e_prob(emissions, N_states):\n",
    "    # Calculate probabilities\n",
    "    emissions_probs = {} # dictionary definition\n",
    "    for key, value in emissions.items(): # iterate through dicitionary \n",
    "        curr_state = key[0]\n",
    "        # count(given s, find w) / given s\n",
    "        emissions_probs[key] = value / N_states[curr_state]\n",
    "\n",
    "    return emissions_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_probs = calculate_e_prob(emissions, N_states)\n",
    "# e_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dummy', ' '), 2.6165681092678842e-05),\n",
       " (('NNP', 'Pierre'), 6.84868961738654e-05),\n",
       " (('NNP', 'Vinken'), 2.2828965391288468e-05)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e_probs.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the greedy decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predicting the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `greedy.out`, in the same format of training data\n",
    "5. [ ] Evaluate the results of the model on `eval.py` in the terminal with `python eval.py − p {predicted file} − g {gold-standard file}`\n",
    "6. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_dev_df.head(40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\" \n",
    "t(all_pos_tags | s) * e(The | all_pos_tags)\n",
    "\n",
    "t(t_find_pos_tag | t_given_pos_tag) * e(e_word | e_given_pos_tag)\n",
    "\n",
    "t(NNP | dummy) * e(_ | NNP) = s1\n",
    "t(, | dummy) * e(_ | ,) = s2\n",
    "t(CD | dummy) * e(_ | CD) = s3\n",
    "--- Get the largest: argmax(s1, s2, s3); say it's s1, so NNP\n",
    "\n",
    "...reset score to 0 bc we update POS Tag, dummy -> s1\n",
    "\n",
    "t(NNP | NNP) * e(The | NNP) = s1\n",
    "t(, | NNP) * e(The | NNP) = s2\n",
    "t(CD | NNP) * e(The | NNP) = s3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(dev_df: pd.DataFrame, t_probs: dict, e_probs: dict, N_pos_tags: np.array):\n",
    "    \"\"\"Implement greedy decoding on the development file (words only) using the transition probability and emission probability. \n",
    "    Furthermore, don't use POS Tag of development file, thus only use POS Tag from training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        Dev file\n",
    "\n",
    "    t_probs: `py dict`\n",
    "        Tranision probabilities for POS Tag given previous POS Tag\n",
    "\n",
    "    e_probs: `py dict`\n",
    "        Emission probabilities for Word given POS Tags\n",
    "\n",
    "    N_pos_tags: `np.array`\n",
    "        All POS Tags found in the training file\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    previous_pos_tag = \"dummy\"\n",
    "    all_max_scores_with_pos_tag = {}\n",
    "    \n",
    "    for index, row in tqdm(dev_df.iterrows(), total=dev_df.shape[0]):\n",
    "        # print(\"index\", index, \"with word\", row['Word'])\n",
    "        # print(\"with POS tag from dev\", row['POS Tag'])\n",
    "\n",
    "\n",
    "        store_scores = []\n",
    "        for N_pos_tags_idx in range(len(N_pos_tags)):\n",
    "            current_pos_tag = N_pos_tags[N_pos_tags_idx]\n",
    "            # print(\"--- Current POS Tag: \", current_pos_tag)\n",
    "\n",
    "            \"\"\"Transition\"\"\"\n",
    "            t_find_pos_tag = current_pos_tag\n",
    "            t_given_pos_tag = previous_pos_tag\n",
    "            # print(f\"--- t({t_find_pos_tag} | {t_given_pos_tag})\")\n",
    "            \n",
    "            \"\"\"Emission\"\"\"\n",
    "            e_word = row['Word']\n",
    "            e_given_pos_tag = current_pos_tag\n",
    "            # print(f\"--- e({e_given_pos_tag} | {e_word})\") # order this way to match e_probs dictionary\n",
    "            \n",
    "            \"\"\"Transition * Emission\"\"\"\n",
    "            t_key = (t_find_pos_tag, t_given_pos_tag)\n",
    "            e_key = (e_given_pos_tag, e_word)\n",
    "            # print(t_key in t_probs, e_key in e_probs)\n",
    "\n",
    "            # IF-ELSE bc not all pairs will be found. If pair is found, use score, otherwise (pair isn't found) set score to 0.0.\n",
    "            if t_key in t_probs and e_key in e_probs:\n",
    "                t = t_probs[t_key]\n",
    "                e = e_probs[e_key]\n",
    "                score = t * e\n",
    "                # print(f\"--- t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "                \n",
    "            else:\n",
    "                t = 0.0\n",
    "                e = 0.0\n",
    "                score = t * e\n",
    "                # print(f\"--- t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "                        \n",
    "            store_scores.append(score)\n",
    "        # print(f\"Scores\", store_scores)\n",
    "        max_score_idx = np.argmax(np.array(store_scores)) # use argmax to get the index of max score\n",
    "        # all_max_scores_with_pos_tag[max_score_idx] = max_score_idx\n",
    "        current_pos_tag = N_pos_tags[max_score_idx] # use the index of the max score to find which POS Tag to update to\n",
    "        # print(\"Updated POS Tag\", current_pos_tag)\n",
    "        # print()\n",
    "        \n",
    "    \n",
    "    # return all_max_scores_with_pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 137295/137295 [00:23<00:00, 5852.38it/s]\n"
     ]
    }
   ],
   "source": [
    "greedy_decoding(updated_dev_df, t_probs, e_probs, all_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Viterbi Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the viterbi decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predict the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `viterbi.out`, in the same format of training data\n",
    "5. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Base case\n",
    "pi[1, all_pos_tags_in_dev_file] = t(all_pos_tags_in_dev_file | s) * e(words | all_pos_tags_in_dev_file)\n",
    "\n",
    "pi[1, all_pos_tags_in_dev_file] = t(t_find_pos_tag | t_given_pos_tag) * e(e_word | e_given_pos_tag)\n",
    "\n",
    "pi[1, dummy] = t(_ | dummy) * e(The | dummy) = s1\n",
    "pi[1, DT] = t(_ | DT) * e(The | DT) = s2\n",
    "pi[1, NNP] = t(_| NNP) * e(The | NNP) = s3\n",
    "\n",
    "...reset score to 0 bc we update POS Tag, dummy -> s1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_dev_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(dev_df: pd.DataFrame, t_probs: dict, e_probs: dict, N_pos_tags: np.array):\n",
    "    \"\"\"Implement greedy decoding on the development file (words only) using the transition probability and emission probability. \n",
    "    \n",
    "    \n",
    "    ??? Furthermore, don't use POS Tag of development file, thus only use POS Tag from training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        Dev file\n",
    "\n",
    "    t_probs: `py dict`\n",
    "        Tranision probabilities for POS Tag given previous POS Tag\n",
    "\n",
    "    e_probs: `py dict`\n",
    "        Emission probabilities for Word given POS Tags\n",
    "\n",
    "    N_pos_tags: `np.array`\n",
    "        All POS Tags found in the training file\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    previous_pos_tag = \"dummy\"\n",
    "    v_pi = {}\n",
    "\n",
    "    \"\"\"Base cases\"\"\"\n",
    "    for index, row in tqdm(dev_df.iterrows(), total=dev_df.shape[0]):\n",
    "        print(\"index\", index, \"with word\", row['Word'], \"and POS tag from dev\", row['POS Tag'])\n",
    "        \n",
    "        current_pos_tag = row['POS Tag']\n",
    "        v_pi_key = (1, current_pos_tag)\n",
    "\n",
    "        \"\"\"Base case\n",
    "        pi[1, all_pos_tags_in_dev_file] = t(all_pos_tags_in_dev_file | s) * e(words | all_pos_tags_in_dev_file)\n",
    "        \n",
    "        pi[1, all_pos_tags_in_dev_file] = t(t_find_pos_tag | t_given_pos_tag) * e(e_word | e_given_pos_tag)\n",
    "        \n",
    "        pi[1, dummy] = t(_ | dummy) * e(The | dummy) = s1\n",
    "        pi[1, DT] = t(_ | DT) * e(The | DT) = s2\n",
    "        pi[1, NNP] = t(_| NNP) * e(The | NNP) = s3\n",
    "        \n",
    "        ...reset score to 0 bc we update POS Tag, dummy -> s1\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"Transition\"\"\"\n",
    "        t_given_pos_tag = \n",
    "        t_find_pos_tag = \n",
    "        t_key = (t_given_pos_tag, t_find_pos_tag)\n",
    "\n",
    "        \"\"\"Emission\"\"\"\n",
    "        \n",
    "        v_pi_value = \n",
    "        v_pi[v_pi_key] = v_pi_value\n",
    "\n",
    "        \"\"\"Transition\"\"\"\n",
    "        \n",
    "        # current_pos_tag = N_pos_tags[max_score_idx]\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 4800.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 with word   and POS tag from dev dummy\n",
      "\n",
      "index 1 with word The and POS tag from dev DT\n",
      "\n",
      "index 2 with word Arizona and POS tag from dev NNP\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "viterbi_decoding(updated_dev_df[:3], t_probs, e_probs, all_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
