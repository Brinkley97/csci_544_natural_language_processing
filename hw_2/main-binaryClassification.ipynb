{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2- Binary Classification \n",
    "- Detravious Jamari Brinkley\n",
    "- CSCI-544: Applied Natural Language Processing\n",
    "- python version: 3.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brinkley97/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "1. Read data\n",
    "2. Keep reviews and ratings\n",
    "3. Create binary and ternary classes\n",
    "4. Clean data steps\n",
    "4. Clean data function\n",
    "5. Split data\n",
    "6. Load pretrained model and train my model\n",
    "    - Get similarity for the pretrained model\n",
    "    - Get similarity for my trained model\n",
    "9. Extract word embeddings\n",
    "    - Get word embeddings for pretrained model\n",
    "    - Get word embeddings for my model\n",
    "10. Simple models\n",
    "    - Get accuracy for perceptron on pretrained model\n",
    "    - Get accuracy for svm on pretrained model\n",
    "    - Get accuracy for perceptron on my model\n",
    "    - Get accuracy for svm on my model\n",
    "11. What do I conclude from comparing performances\n",
    "12. Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"../datasets/amazon_reviews_us_Office_Products_v1_00.tsv\"\n",
    "amazon_reviews_copy_df = pd.read_csv(dataset, sep='\\t', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "0                 5                                     Great product.\n",
       "1                 5  What's to say about this commodity item except...\n",
       "2                 5    Haven't used yet, but I am sure I will like it.\n",
       "3                 1  Although this was labeled as &#34;new&#34; the...\n",
       "4                 4                    Gorgeous colors and easy to use\n",
       "...             ...                                                ...\n",
       "2640249           4  I can't live anymore whithout my Palm III. But...\n",
       "2640250           4  Although the Palm Pilot is thin and compact it...\n",
       "2640251           4  This book had a lot of great content without b...\n",
       "2640252           5  I am teaching a course in Excel and am using t...\n",
       "2640253           5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640254 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ratings_df = amazon_reviews_copy_df.loc[0:, ['star_rating', 'review_body']]\n",
    "reviews_ratings_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_reviews(df: pd.DataFrame, review_col_name: str, number_of_reviews: int = 3):\n",
    "    \"\"\"Include reviews and ratings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    review_col_name: `str`\n",
    "        The specific_column to get the reviews and ratings of\n",
    "    \n",
    "    number_of_reviews: `int`\n",
    "        Number of samples to include\n",
    "\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Nothing; instead, print the reviews with ratings\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    columns_to_include = [review_col_name, 'star_rating']\n",
    "\n",
    "    # Initialize an empty list to store dictionaries\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Iterate over the specified columns and retrieve the first three rows\n",
    "    for row in df[columns_to_include].head(3).to_dict(orient='records'):\n",
    "        list_of_dicts.append({'star_rating': row['star_rating'], review_col_name: row[review_col_name]})\n",
    "\n",
    "    for dictionary in list_of_dicts:\n",
    "        print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create binary and ternary classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data_type(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Update the data type of the star ratings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with rating values\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the new sentiment appened\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    valid_ratings = ['1','2','3','4','5']\n",
    "    star_rating_series = df[col_name].copy()\n",
    "\n",
    "    # Convert type to strings\n",
    "    star_rating_series.astype('str')\n",
    "\n",
    "    # Check valid list and see which of our stars match\n",
    "    rows = star_rating_series.index\n",
    "    is_rating_in_valid_ratings = rows[star_rating_series.isin(valid_ratings)]\n",
    "\n",
    "    # Convert to list\n",
    "    is_rating_in_valid_ratings = is_rating_in_valid_ratings.to_list()\n",
    "\n",
    "    updated_df = df.iloc[is_rating_in_valid_ratings]\n",
    "    updated_df[col_name] = updated_df[col_name].astype(int)\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_78622/2907883124.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_df[col_name] = updated_df[col_name].astype(int)\n"
     ]
    }
   ],
   "source": [
    "updated_reviews_ratings_df = update_data_type(reviews_ratings_df, 'star_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5                                     Great product.\n",
       "1                  5  What's to say about this commodity item except...\n",
       "2                  5    Haven't used yet, but I am sure I will like it.\n",
       "3                  1  Although this was labeled as &#34;new&#34; the...\n",
       "4                  4                    Gorgeous colors and easy to use\n",
       "...              ...                                                ...\n",
       "2640249            4  I can't live anymore whithout my Palm III. But...\n",
       "2640250            4  Although the Palm Pilot is thin and compact it...\n",
       "2640251            4  This book had a lot of great content without b...\n",
       "2640252            5  I am teaching a course in Excel and am using t...\n",
       "2640253            5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640237 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5                                     Great product.\n",
       "1                  5  What's to say about this commodity item except...\n",
       "2                  5    Haven't used yet, but I am sure I will like it.\n",
       "3                  1  Although this was labeled as &#34;new&#34; the...\n",
       "4                  4                    Gorgeous colors and easy to use\n",
       "...              ...                                                ...\n",
       "2640249            4  I can't live anymore whithout my Palm III. But...\n",
       "2640250            4  Although the Palm Pilot is thin and compact it...\n",
       "2640251            4  This book had a lot of great content without b...\n",
       "2640252            5  I am teaching a course in Excel and am using t...\n",
       "2640253            5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640080 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_reviews_ratings_df = updated_reviews_ratings_df.dropna()\n",
    "updated_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         star_rating  review_body\n",
      "0              False        False\n",
      "1              False        False\n",
      "2              False        False\n",
      "3              False        False\n",
      "4              False        False\n",
      "...              ...          ...\n",
      "2640249        False        False\n",
      "2640250        False        False\n",
      "2640251        False        False\n",
      "2640252        False        False\n",
      "2640253        False        False\n",
      "\n",
      "[2640080 rows x 2 columns]\n",
      "There are no NaN values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "nan_check = updated_reviews_ratings_df.isna()\n",
    "\n",
    "# Display the DataFrame with True where NaN values exist\n",
    "print(nan_check)\n",
    "\n",
    "# Check if any NaN value exists in the DataFrame\n",
    "if nan_check.any().any():\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reviews per rating star_rating\n",
      "5    1582704\n",
      "4     418348\n",
      "1     306967\n",
      "3     193680\n",
      "2     138381\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"# reviews per rating\", updated_reviews_ratings_df['star_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_star_ratings(df: pd.DataFrame, col_name: str, star_value: int, number_of_reviews: int):\n",
    "    \"\"\"Build a subset balanced dataset with reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The dataframe to use\n",
    "    col_name: `str`\n",
    "        The name of the column to get reviews from\n",
    "    star_value: `int`\n",
    "        The star rating of the review\n",
    "    number_of_reviews: `int`\n",
    "        The number of sub reviews to include in sample\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    rating_df, sampled_rating_df: `tuple`\n",
    "        All reviews with that rating and the subset reviews with that rating\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_df = df[df[col_name] == star_value]\n",
    "    sampled_rating_df = rating_df.sample(n=number_of_reviews)\n",
    "    return rating_df, sampled_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_reviews = 50000\n",
    "subset_reviews = 300\n",
    "\n",
    "one_star = 1\n",
    "rating_one, rating_one_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', one_star, subset_reviews)\n",
    "two_stars = 2\n",
    "rating_two, rating_two_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', two_stars, subset_reviews)\n",
    "three_stars = 3\n",
    "rating_three, rating_three_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', three_stars, subset_reviews)\n",
    "four_stars = 4\n",
    "rating_four, rating_four_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', four_stars, subset_reviews)\n",
    "five_stars = 5\n",
    "rating_five, rating_five_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', five_stars, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reviews_df = pd.concat([rating_one_sampled, rating_two_sampled, rating_three_sampled, rating_four_sampled, rating_five_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525783</th>\n",
       "      <td>1</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880086</th>\n",
       "      <td>1</td>\n",
       "      <td>Years ago we had an HP printer that created al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208773</th>\n",
       "      <td>1</td>\n",
       "      <td>In less than one month of use, the yellow tone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015475</th>\n",
       "      <td>1</td>\n",
       "      <td>I have no luck getting any support (human) to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833772</th>\n",
       "      <td>1</td>\n",
       "      <td>Although it didn't slip right into place like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461079</th>\n",
       "      <td>5</td>\n",
       "      <td>Not sure how I've been teaching for 4 years wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603521</th>\n",
       "      <td>5</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232082</th>\n",
       "      <td>5</td>\n",
       "      <td>Very happy with the bubble wrap and speedy del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582464</th>\n",
       "      <td>5</td>\n",
       "      <td>I had no problems at all with this printer.  A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361289</th>\n",
       "      <td>5</td>\n",
       "      <td>The time had come for a new standard home phon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "525783             1  feeble and fragile ... good design idea... inf...\n",
       "880086             1  Years ago we had an HP printer that created al...\n",
       "2208773            1  In less than one month of use, the yellow tone...\n",
       "1015475            1  I have no luck getting any support (human) to ...\n",
       "1833772            1  Although it didn't slip right into place like ...\n",
       "...              ...                                                ...\n",
       "1461079            5  Not sure how I've been teaching for 4 years wi...\n",
       "1603521            5  like it alot, holds up well on the outside of ...\n",
       "1232082            5  Very happy with the bubble wrap and speedy del...\n",
       "2582464            5  I had no problems at all with this printer.  A...\n",
       "1361289            5  The time had come for a new standard home phon...\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_reviews_by_rating(df: pd.DataFrame, rating_col: str, threshold: int, sentiment_type: str):\n",
    "    \"\"\"Categorizes reviews by adding a rating\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    rating_col: `str`\n",
    "        Column with rating values\n",
    "    \n",
    "    threshold: `int`\n",
    "        Where to split the ratings such that categories can be formed\n",
    "\n",
    "    sentiment_type: `str`\n",
    "        One of three types of sentiment: positive, negative, or neural\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the new sentiment appened\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if sentiment_type == 'positive_review_class':\n",
    "        positive_review_threshold = df[rating_col].astype('int32') > threshold\n",
    "        df = df[positive_review_threshold]\n",
    "        df[sentiment_type] = 1\n",
    "\n",
    "    elif sentiment_type == 'negative_review_class':\n",
    "        negative_review_threshold = df[rating_col].astype('int32') < threshold\n",
    "        df = df[negative_review_threshold]\n",
    "        df[sentiment_type] = 2\n",
    "\n",
    "    elif sentiment_type == 'neutral_review_class':\n",
    "        neutral_review_threshold = df[rating_col].astype('int32') == threshold\n",
    "        df = df[neutral_review_threshold]\n",
    "        df[sentiment_type] = 3\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_78622/637639312.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 2\n",
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_78622/637639312.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 3\n",
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_78622/637639312.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 1\n"
     ]
    }
   ],
   "source": [
    "negative_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'negative_review_class')\n",
    "neutral_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'neutral_review_class')\n",
    "positive_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'positive_review_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>negative_review_class</th>\n",
       "      <th>neutral_review_class</th>\n",
       "      <th>positive_review_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525783</th>\n",
       "      <td>1</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880086</th>\n",
       "      <td>1</td>\n",
       "      <td>Years ago we had an HP printer that created al...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208773</th>\n",
       "      <td>1</td>\n",
       "      <td>In less than one month of use, the yellow tone...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015475</th>\n",
       "      <td>1</td>\n",
       "      <td>I have no luck getting any support (human) to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833772</th>\n",
       "      <td>1</td>\n",
       "      <td>Although it didn't slip right into place like ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461079</th>\n",
       "      <td>5</td>\n",
       "      <td>Not sure how I've been teaching for 4 years wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603521</th>\n",
       "      <td>5</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232082</th>\n",
       "      <td>5</td>\n",
       "      <td>Very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582464</th>\n",
       "      <td>5</td>\n",
       "      <td>I had no problems at all with this printer.  A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361289</th>\n",
       "      <td>5</td>\n",
       "      <td>The time had come for a new standard home phon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "525783             1  feeble and fragile ... good design idea... inf...   \n",
       "880086             1  Years ago we had an HP printer that created al...   \n",
       "2208773            1  In less than one month of use, the yellow tone...   \n",
       "1015475            1  I have no luck getting any support (human) to ...   \n",
       "1833772            1  Although it didn't slip right into place like ...   \n",
       "...              ...                                                ...   \n",
       "1461079            5  Not sure how I've been teaching for 4 years wi...   \n",
       "1603521            5  like it alot, holds up well on the outside of ...   \n",
       "1232082            5  Very happy with the bubble wrap and speedy del...   \n",
       "2582464            5  I had no problems at all with this printer.  A...   \n",
       "1361289            5  The time had come for a new standard home phon...   \n",
       "\n",
       "         negative_review_class  neutral_review_class  positive_review_class  \n",
       "525783                     2.0                   NaN                    NaN  \n",
       "880086                     2.0                   NaN                    NaN  \n",
       "2208773                    2.0                   NaN                    NaN  \n",
       "1015475                    2.0                   NaN                    NaN  \n",
       "1833772                    2.0                   NaN                    NaN  \n",
       "...                        ...                   ...                    ...  \n",
       "1461079                    NaN                   NaN                    1.0  \n",
       "1603521                    NaN                   NaN                    1.0  \n",
       "1232082                    NaN                   NaN                    1.0  \n",
       "2582464                    NaN                   NaN                    1.0  \n",
       "1361289                    NaN                   NaN                    1.0  \n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_ratings_df = pd.concat([negative_review_class_df, neutral_review_class_df, positive_review_class_df])\n",
    "sampled_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_df = sampled_reviews_ratings_df['negative_review_class'].dropna()\n",
    "neutral_reviews_df = sampled_reviews_ratings_df['neutral_review_class'].dropna()\n",
    "positive_reviews_df = sampled_reviews_ratings_df['positive_review_class'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reviews_ratings_df['binary_review_class'] = pd.concat([negative_reviews_df, positive_reviews_df])\n",
    "sampled_reviews_ratings_df['ternary_review_class'] = pd.concat([negative_reviews_df, neutral_reviews_df, positive_reviews_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., nan,  1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_ratings_df['binary_review_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_reviews_to_lower_case(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Convert all reviews to lower case\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the lower cased reviews\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_case_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    \n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "        # print(text_reviews_idx, type(text_review), text_review)\n",
    "\n",
    "        # NOT all reviews are strings, thus all can't be converted to lower cased\n",
    "        if type(text_review) != str:\n",
    "            print(True, text_review)\n",
    "            converted_str = str(text_review)\n",
    "            lower_case_reviews.append(text_review)\n",
    "         \n",
    "        else:\n",
    "            update_text_review = text_review.lower()\n",
    "            lower_case_reviews.append(update_text_review)\n",
    "\n",
    "    updated_df['lower_cased'] = lower_case_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_lower_cased = convert_reviews_to_lower_case(sampled_reviews_ratings_df, 'review_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_lower_cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"reviews_lower_cased:\")\n",
    "# generate_sample_reviews(reviews_lower_cased, 'lower_cased', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_urls(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove HTML and URLs from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the html_and_urls removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # url_pattern = re.compile(r'https?://\\S+|www\\. \\S+')\n",
    "\n",
    "    cleaned_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "            # Check and remove HTML tags\n",
    "            has_html = bool(re.search('<.*?>', text_review))\n",
    "            if has_html == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has HTML -- \", text_review)\n",
    "                pass\n",
    "\n",
    "            no_html_review = re.sub('<.*?>', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without HTML -- \", no_html_review)\n",
    "        \n",
    "            # Check and remove URLs\n",
    "            has_url = bool(re.search(r'http\\S+', no_html_review))\n",
    "            if has_url == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has URL --\", no_html_review)\n",
    "                pass\n",
    "\n",
    "            no_html_url_review = re.sub(r'http\\S+', '', no_html_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without HTML, URL -- \", no_html_url_review)\n",
    "            # print()\n",
    "            cleaned_reviews.append(no_html_url_review)\n",
    "        else:\n",
    "            # print(text_reviews_idx, text_review)\n",
    "            cleaned_reviews.append(text_review)\n",
    "            \n",
    "\n",
    "    updated_df['without_html_urls'] = cleaned_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_html_urls_df = remove_html_and_urls(reviews_lower_cased, 'lower_cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_html_urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_html_urls:\")\n",
    "# generate_sample_reviews(no_html_urls_df, 'without_html_urls', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'd\": \"what would\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when'll\": \"when will\",\n",
    "    \"when'd\": \"when would\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where'll\": \"where will\",\n",
    "    \"where'd\": \"where would\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why'll\": \"why will\",\n",
    "    \"why'd\": \"why would\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how'd\": \"how would\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_and_replace_contractions(review):\n",
    "    \"\"\"Find the contractions to replace from a specific review\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    review: `str`\n",
    "        A specific review\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    non_contraction_review: `str`\n",
    "        The updated specific review with contractions expanded\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(review, str):\n",
    "        get_words = review.split()\n",
    "\n",
    "        store_non_contraction_words = []\n",
    "\n",
    "        for word in get_words:\n",
    "            if word in store_contractions:\n",
    "                non_contraction_form = store_contractions[word]\n",
    "                # print(word, \"-->\", non_contraction_form)\n",
    "\n",
    "                store_non_contraction_words.append(non_contraction_form)\n",
    "\n",
    "            else:\n",
    "                # print(word)\n",
    "                store_non_contraction_words.append(word)\n",
    "\n",
    "        non_contraction_review = ' '.join(store_non_contraction_words)\n",
    "        return non_contraction_review\n",
    "    else:\n",
    "        return review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contractions(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove contractions from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    without_contractions_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        # print(\"Review\", text_reviews_idx, \"with possible contraction(s) -- \", text_review)\n",
    "\n",
    "        without_contraction = locate_and_replace_contractions(text_review)\n",
    "\n",
    "        # print(\"Review\", text_reviews_idx, \"without contraction -- \", without_contraction)\n",
    "        # print()\n",
    "\n",
    "        without_contractions_reviews.append(without_contraction)\n",
    "\n",
    "    updated_df['without_contractions'] = without_contractions_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_contractions_df = remove_contractions(no_html_urls_df, 'without_html_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_contractions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_contractions:\")\n",
    "# generate_sample_reviews(no_contractions_df, 'without_contractions', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabetical_characters(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove Non-alphabetical characters from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the non-alphabetical characters removed\n",
    "    \"\"\"\n",
    "\n",
    "    alphabetical_char_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    # print(text_reviews)\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "        \n",
    "        if isinstance(text_review, str):\n",
    "\n",
    "            # Check for non-alphabetical characters\n",
    "            has_non_alphabetical_char = bool(re.search(r'[^a-zA-Z]', text_review))\n",
    "            if has_non_alphabetical_char == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has HTML -- \", text_review)\n",
    "                pass\n",
    "            \n",
    "            # Remove non-alphabetical characters\n",
    "            with_alphabetical_char = re.sub(r'[^a-zA-Z\\s]', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"has HTML -- \", with_alphabetical_char)\n",
    "            alphabetical_char_reviews.append(with_alphabetical_char)\n",
    "        else:\n",
    "            alphabetical_char_reviews.append(text_review)\n",
    "\n",
    "    updated_df['with_alpha_chars_only'] = alphabetical_char_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_alpha_chars_df = remove_non_alphabetical_characters(no_contractions_df, 'without_contractions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_alpha_chars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"with_alpha_chars_only:\")\n",
    "# generate_sample_reviews(only_alpha_chars_df, 'with_alpha_chars_only', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove extra spaces from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    single_spaced_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    # print(text_reviews)\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "        # Check if there are any extra spaces\n",
    "            has_extra_space = bool(re.search(r' +', text_review))\n",
    "            if has_extra_space == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has extra space -- \", text_review)\n",
    "                pass\n",
    "            \n",
    "            # Remove extra spaces\n",
    "            single_spaced_review = re.sub(r' +', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without extra space -- \", single_spaced_review)\n",
    "            # print()\n",
    "            \n",
    "            single_spaced_reviews.append(single_spaced_review)\n",
    "        else:\n",
    "            single_spaced_reviews.append(text_review)\n",
    "\n",
    "    updated_df['without_extra_space'] = single_spaced_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_extra_space_df = remove_extra_spaces(only_alpha_chars_df, 'with_alpha_chars_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_extra_space_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_extra_space:\")\n",
    "# generate_sample_reviews(no_extra_space_df, 'without_extra_space', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Filter stop words out from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    without_stop_words_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "            text_review_words = word_tokenize(text_review) \n",
    "\n",
    "        \n",
    "\n",
    "            # print(\"Before stop word removal\", text_reviews_idx, \" -- \", text_review)\n",
    "\n",
    "            filtered_review = []\n",
    "\n",
    "            for text_review_words_idx in range(len(text_review_words)):\n",
    "                text_review_word = text_review_words[text_review_words_idx]\n",
    "                \n",
    "                # Check if review word is a stop word\n",
    "                if text_review_word in stop_words:\n",
    "                    # print(\"  Stop word -- \", text_review_word)\n",
    "                    pass\n",
    "                else:\n",
    "                    # print(text_review_word, \" -- is NOT a stop word in review\")\n",
    "                    filtered_review.append(text_review_word)\n",
    "\n",
    "            \n",
    "            filtered_review = \" \".join(filtered_review)\n",
    "            # print(\"After stop word removal\", text_reviews_idx, \" -- \", filtered_review)\n",
    "            # print()\n",
    "            \n",
    "            without_stop_words_reviews.append(filtered_review)\n",
    "        else:\n",
    "            without_stop_words_reviews.append(text_review)\n",
    "        \n",
    "\n",
    "    updated_df['without_stop_words'] = without_stop_words_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_stop_words_df = filter_stop_words(no_extra_space_df, 'without_extra_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_stop_words:\")\n",
    "# generate_sample_reviews(no_stop_words_df, 'without_stop_words', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform lemmatization  \n",
    "\n",
    "- \"A sentence with many words\"\n",
    "    - \"words\" -> word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmentize_review(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Lemmentize all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    lemmed_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]   \n",
    "        if isinstance(text_review, str):     \n",
    "            words_in_review = word_tokenize(text_review) \n",
    "\n",
    "            # print(\"Before lem update\", text_reviews_idx, \" -- \", text_review)\n",
    "            # print(\"Lemmed words\", words_in_review)\n",
    "            \n",
    "\n",
    "            lemmed_sentence = []\n",
    "\n",
    "            # Split review into words\n",
    "            for lemmed_words_idx in range(len(words_in_review)):\n",
    "                word = words_in_review[lemmed_words_idx]\n",
    "                \n",
    "                apply_lemmatization = lem.lemmatize(word)\n",
    "                # print(apply_lemmatization)\n",
    "                \n",
    "                lemmed_sentence.append(apply_lemmatization)\n",
    "                filtered_review = \" \".join(lemmed_sentence)\n",
    "        \n",
    "            # print(\"After lem update -- \", filtered_review)\n",
    "            # print()\n",
    "\n",
    "            lemmed_reviews.append(filtered_review)\n",
    "        else:\n",
    "            lemmed_reviews.append(text_review)\n",
    "\n",
    "    updated_df['lemmed_reviews'] = lemmed_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmed_df = lemmentize_review(no_stop_words_df, 'without_stop_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_unlemmed_words:\")\n",
    "# generate_sample_reviews(lemmed_df, 'lemmed_reviews', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, col_name):\n",
    "    \"\"\"Perform lower case, remove HTML and URLs, remove contractions, remove non-alphabetical characters, remove extra spaces, remove stop words, and lemmatize\"\"\"\n",
    "\n",
    "    print(\"original reviews:\")\n",
    "    generate_sample_reviews(df, col_name, 3)\n",
    "\n",
    "    reviews_lower_cased = convert_reviews_to_lower_case(df, col_name)\n",
    "    print(\"reviews_lower_cased:\")\n",
    "    generate_sample_reviews(reviews_lower_cased, 'lower_cased', 3)\n",
    "\n",
    "    no_html_urls_df = remove_html_and_urls(reviews_lower_cased, 'lower_cased')\n",
    "    print(\"without_html_urls:\")\n",
    "    generate_sample_reviews(no_html_urls_df, 'without_html_urls', 3)\n",
    "\n",
    "    no_contractions_df = remove_contractions(no_html_urls_df, 'without_html_urls')\n",
    "    print(\"without_contractions:\")\n",
    "    generate_sample_reviews(no_contractions_df, 'without_contractions', 3)\n",
    "\n",
    "    only_alpha_chars_df = remove_non_alphabetical_characters(no_contractions_df, 'without_contractions')\n",
    "    print(\"with_alpha_chars_only:\")\n",
    "    generate_sample_reviews(only_alpha_chars_df, 'with_alpha_chars_only', 3)\n",
    "\n",
    "    no_extra_space_df = remove_extra_spaces(only_alpha_chars_df, 'with_alpha_chars_only')\n",
    "    print(\"without_extra_space:\")\n",
    "    generate_sample_reviews(no_extra_space_df, 'without_extra_space', 3)\n",
    "\n",
    "    no_stop_words_df = filter_stop_words(no_extra_space_df, 'without_extra_space')\n",
    "    print(\"without_stop_words:\")\n",
    "    generate_sample_reviews(no_stop_words_df, 'without_stop_words', 3)\n",
    "    \n",
    "    lemmed_df = lemmentize_review(no_stop_words_df, 'without_stop_words')\n",
    "    print(\"without_unlemmed_words:\")\n",
    "    generate_sample_reviews(lemmed_df, 'lemmed_reviews', 3)\n",
    "\n",
    "    return lemmed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original reviews:\n",
      "{'star_rating': 1, 'review_body': 'feeble and fragile ... good design idea... inferior joint materials ... three dimensional joints w/ soft plastic ...'}\n",
      "{'star_rating': 1, 'review_body': 'Years ago we had an HP printer that created all kinds of havoc with Windows.  Now we have the HP Officejet 4630 and it too is creating all kinds of havoc.  Finally have learned our lesson, NO MORE HP PRINTERS.  Worked fine for few months and now only light blue printing, colors strong but no black print.  Did all the troubleshooting, re-installed, etc etc and now have drop kicked it out the door.'}\n",
      "{'star_rating': 1, 'review_body': 'In less than one month of use, the yellow toner exploded inside of our machine. There is yellow toner dust everywhere in and around out printer! This is not acceptable. The blue has began to drip blue dust as well inside the printer.'}\n",
      "reviews_lower_cased:\n",
      "{'star_rating': 1, 'lower_cased': 'feeble and fragile ... good design idea... inferior joint materials ... three dimensional joints w/ soft plastic ...'}\n",
      "{'star_rating': 1, 'lower_cased': 'years ago we had an hp printer that created all kinds of havoc with windows.  now we have the hp officejet 4630 and it too is creating all kinds of havoc.  finally have learned our lesson, no more hp printers.  worked fine for few months and now only light blue printing, colors strong but no black print.  did all the troubleshooting, re-installed, etc etc and now have drop kicked it out the door.'}\n",
      "{'star_rating': 1, 'lower_cased': 'in less than one month of use, the yellow toner exploded inside of our machine. there is yellow toner dust everywhere in and around out printer! this is not acceptable. the blue has began to drip blue dust as well inside the printer.'}\n",
      "without_html_urls:\n",
      "{'star_rating': 1, 'without_html_urls': 'feeble and fragile ... good design idea... inferior joint materials ... three dimensional joints w/ soft plastic ...'}\n",
      "{'star_rating': 1, 'without_html_urls': 'years ago we had an hp printer that created all kinds of havoc with windows.  now we have the hp officejet 4630 and it too is creating all kinds of havoc.  finally have learned our lesson, no more hp printers.  worked fine for few months and now only light blue printing, colors strong but no black print.  did all the troubleshooting, re-installed, etc etc and now have drop kicked it out the door.'}\n",
      "{'star_rating': 1, 'without_html_urls': 'in less than one month of use, the yellow toner exploded inside of our machine. there is yellow toner dust everywhere in and around out printer! this is not acceptable. the blue has began to drip blue dust as well inside the printer.'}\n",
      "without_contractions:\n",
      "{'star_rating': 1, 'without_contractions': 'feeble and fragile ... good design idea... inferior joint materials ... three dimensional joints w/ soft plastic ...'}\n",
      "{'star_rating': 1, 'without_contractions': 'years ago we had an hp printer that created all kinds of havoc with windows. now we have the hp officejet 4630 and it too is creating all kinds of havoc. finally have learned our lesson, no more hp printers. worked fine for few months and now only light blue printing, colors strong but no black print. did all the troubleshooting, re-installed, etc etc and now have drop kicked it out the door.'}\n",
      "{'star_rating': 1, 'without_contractions': 'in less than one month of use, the yellow toner exploded inside of our machine. there is yellow toner dust everywhere in and around out printer! this is not acceptable. the blue has began to drip blue dust as well inside the printer.'}\n",
      "with_alpha_chars_only:\n",
      "{'star_rating': 1, 'with_alpha_chars_only': 'feeble and fragile     good design idea    inferior joint materials     three dimensional joints w  soft plastic    '}\n",
      "{'star_rating': 1, 'with_alpha_chars_only': 'years ago we had an hp printer that created all kinds of havoc with windows  now we have the hp officejet      and it too is creating all kinds of havoc  finally have learned our lesson  no more hp printers  worked fine for few months and now only light blue printing  colors strong but no black print  did all the troubleshooting  re installed  etc etc and now have drop kicked it out the door '}\n",
      "{'star_rating': 1, 'with_alpha_chars_only': 'in less than one month of use  the yellow toner exploded inside of our machine  there is yellow toner dust everywhere in and around out printer  this is not acceptable  the blue has began to drip blue dust as well inside the printer '}\n",
      "without_extra_space:\n",
      "{'star_rating': 1, 'without_extra_space': 'feeble and fragile good design idea inferior joint materials three dimensional joints w soft plastic '}\n",
      "{'star_rating': 1, 'without_extra_space': 'years ago we had an hp printer that created all kinds of havoc with windows now we have the hp officejet and it too is creating all kinds of havoc finally have learned our lesson no more hp printers worked fine for few months and now only light blue printing colors strong but no black print did all the troubleshooting re installed etc etc and now have drop kicked it out the door '}\n",
      "{'star_rating': 1, 'without_extra_space': 'in less than one month of use the yellow toner exploded inside of our machine there is yellow toner dust everywhere in and around out printer this is not acceptable the blue has began to drip blue dust as well inside the printer '}\n",
      "without_stop_words:\n",
      "{'star_rating': 1, 'without_stop_words': 'feeble fragile good design idea inferior joint materials three dimensional joints w soft plastic'}\n",
      "{'star_rating': 1, 'without_stop_words': 'years ago hp printer created kinds havoc windows hp officejet creating kinds havoc finally learned lesson hp printers worked fine months light blue printing colors strong black print troubleshooting installed etc etc drop kicked door'}\n",
      "{'star_rating': 1, 'without_stop_words': 'less one month use yellow toner exploded inside machine yellow toner dust everywhere around printer acceptable blue began drip blue dust well inside printer'}\n",
      "without_unlemmed_words:\n",
      "{'star_rating': 1, 'lemmed_reviews': 'feeble fragile good design idea inferior joint material three dimensional joint w soft plastic'}\n",
      "{'star_rating': 1, 'lemmed_reviews': 'year ago hp printer created kind havoc window hp officejet creating kind havoc finally learned lesson hp printer worked fine month light blue printing color strong black print troubleshooting installed etc etc drop kicked door'}\n",
      "{'star_rating': 1, 'lemmed_reviews': 'le one month use yellow toner exploded inside machine yellow toner dust everywhere around printer acceptable blue began drip blue dust well inside printer'}\n"
     ]
    }
   ],
   "source": [
    "cleaned_reviews_df = preprocess_data(sampled_reviews_ratings_df, 'review_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>negative_review_class</th>\n",
       "      <th>neutral_review_class</th>\n",
       "      <th>positive_review_class</th>\n",
       "      <th>binary_review_class</th>\n",
       "      <th>ternary_review_class</th>\n",
       "      <th>lower_cased</th>\n",
       "      <th>without_html_urls</th>\n",
       "      <th>without_contractions</th>\n",
       "      <th>with_alpha_chars_only</th>\n",
       "      <th>without_extra_space</th>\n",
       "      <th>without_stop_words</th>\n",
       "      <th>lemmed_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525783</th>\n",
       "      <td>1</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "      <td>feeble and fragile ... good design idea... inf...</td>\n",
       "      <td>feeble and fragile     good design idea    inf...</td>\n",
       "      <td>feeble and fragile good design idea inferior j...</td>\n",
       "      <td>feeble fragile good design idea inferior joint...</td>\n",
       "      <td>feeble fragile good design idea inferior joint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880086</th>\n",
       "      <td>1</td>\n",
       "      <td>Years ago we had an HP printer that created al...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>years ago we had an hp printer that created al...</td>\n",
       "      <td>years ago we had an hp printer that created al...</td>\n",
       "      <td>years ago we had an hp printer that created al...</td>\n",
       "      <td>years ago we had an hp printer that created al...</td>\n",
       "      <td>years ago we had an hp printer that created al...</td>\n",
       "      <td>years ago hp printer created kinds havoc windo...</td>\n",
       "      <td>year ago hp printer created kind havoc window ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208773</th>\n",
       "      <td>1</td>\n",
       "      <td>In less than one month of use, the yellow tone...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>in less than one month of use, the yellow tone...</td>\n",
       "      <td>in less than one month of use, the yellow tone...</td>\n",
       "      <td>in less than one month of use, the yellow tone...</td>\n",
       "      <td>in less than one month of use  the yellow tone...</td>\n",
       "      <td>in less than one month of use the yellow toner...</td>\n",
       "      <td>less one month use yellow toner exploded insid...</td>\n",
       "      <td>le one month use yellow toner exploded inside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015475</th>\n",
       "      <td>1</td>\n",
       "      <td>I have no luck getting any support (human) to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>i have no luck getting any support (human) to ...</td>\n",
       "      <td>i have no luck getting any support (human) to ...</td>\n",
       "      <td>i have no luck getting any support (human) to ...</td>\n",
       "      <td>i have no luck getting any support  human  to ...</td>\n",
       "      <td>i have no luck getting any support human to he...</td>\n",
       "      <td>luck getting support human help setting thing ...</td>\n",
       "      <td>luck getting support human help setting thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833772</th>\n",
       "      <td>1</td>\n",
       "      <td>Although it didn't slip right into place like ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>although it didn't slip right into place like ...</td>\n",
       "      <td>although it didn't slip right into place like ...</td>\n",
       "      <td>although it did not slip right into place like...</td>\n",
       "      <td>although it did not slip right into place like...</td>\n",
       "      <td>although it did not slip right into place like...</td>\n",
       "      <td>although slip right place like old one fit pro...</td>\n",
       "      <td>although slip right place like old one fit pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461079</th>\n",
       "      <td>5</td>\n",
       "      <td>Not sure how I've been teaching for 4 years wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>not sure how i've been teaching for 4 years wi...</td>\n",
       "      <td>not sure how i've been teaching for 4 years wi...</td>\n",
       "      <td>not sure how I have been teaching for 4 years ...</td>\n",
       "      <td>not sure how I have been teaching for   years ...</td>\n",
       "      <td>not sure how I have been teaching for years wi...</td>\n",
       "      <td>sure I teaching years without one even redicul...</td>\n",
       "      <td>sure I teaching year without one even rediculo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603521</th>\n",
       "      <td>5</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "      <td>like it alot, holds up well on the outside of ...</td>\n",
       "      <td>like it alot  holds up well on the outside of ...</td>\n",
       "      <td>like it alot holds up well on the outside of y...</td>\n",
       "      <td>like alot holds well outside door small packag...</td>\n",
       "      <td>like alot hold well outside door small package...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232082</th>\n",
       "      <td>5</td>\n",
       "      <td>Very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>very happy with the bubble wrap and speedy del...</td>\n",
       "      <td>happy bubble wrap speedy delivery</td>\n",
       "      <td>happy bubble wrap speedy delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582464</th>\n",
       "      <td>5</td>\n",
       "      <td>I had no problems at all with this printer.  A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had no problems at all with this printer.  a...</td>\n",
       "      <td>i had no problems at all with this printer.  a...</td>\n",
       "      <td>i had no problems at all with this printer. af...</td>\n",
       "      <td>i had no problems at all with this printer  af...</td>\n",
       "      <td>i had no problems at all with this printer aft...</td>\n",
       "      <td>problems printer receiving problems setting in...</td>\n",
       "      <td>problem printer receiving problem setting inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361289</th>\n",
       "      <td>5</td>\n",
       "      <td>The time had come for a new standard home phon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the time had come for a new standard home phon...</td>\n",
       "      <td>the time had come for a new standard home phon...</td>\n",
       "      <td>the time had come for a new standard home phon...</td>\n",
       "      <td>the time had come for a new standard home phon...</td>\n",
       "      <td>the time had come for a new standard home phon...</td>\n",
       "      <td>time come new standard home phone fit requirem...</td>\n",
       "      <td>time come new standard home phone fit requirem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "525783             1  feeble and fragile ... good design idea... inf...   \n",
       "880086             1  Years ago we had an HP printer that created al...   \n",
       "2208773            1  In less than one month of use, the yellow tone...   \n",
       "1015475            1  I have no luck getting any support (human) to ...   \n",
       "1833772            1  Although it didn't slip right into place like ...   \n",
       "...              ...                                                ...   \n",
       "1461079            5  Not sure how I've been teaching for 4 years wi...   \n",
       "1603521            5  like it alot, holds up well on the outside of ...   \n",
       "1232082            5  Very happy with the bubble wrap and speedy del...   \n",
       "2582464            5  I had no problems at all with this printer.  A...   \n",
       "1361289            5  The time had come for a new standard home phon...   \n",
       "\n",
       "         negative_review_class  neutral_review_class  positive_review_class  \\\n",
       "525783                     2.0                   NaN                    NaN   \n",
       "880086                     2.0                   NaN                    NaN   \n",
       "2208773                    2.0                   NaN                    NaN   \n",
       "1015475                    2.0                   NaN                    NaN   \n",
       "1833772                    2.0                   NaN                    NaN   \n",
       "...                        ...                   ...                    ...   \n",
       "1461079                    NaN                   NaN                    1.0   \n",
       "1603521                    NaN                   NaN                    1.0   \n",
       "1232082                    NaN                   NaN                    1.0   \n",
       "2582464                    NaN                   NaN                    1.0   \n",
       "1361289                    NaN                   NaN                    1.0   \n",
       "\n",
       "         binary_review_class  ternary_review_class  \\\n",
       "525783                   2.0                   2.0   \n",
       "880086                   2.0                   2.0   \n",
       "2208773                  2.0                   2.0   \n",
       "1015475                  2.0                   2.0   \n",
       "1833772                  2.0                   2.0   \n",
       "...                      ...                   ...   \n",
       "1461079                  1.0                   1.0   \n",
       "1603521                  1.0                   1.0   \n",
       "1232082                  1.0                   1.0   \n",
       "2582464                  1.0                   1.0   \n",
       "1361289                  1.0                   1.0   \n",
       "\n",
       "                                               lower_cased  \\\n",
       "525783   feeble and fragile ... good design idea... inf...   \n",
       "880086   years ago we had an hp printer that created al...   \n",
       "2208773  in less than one month of use, the yellow tone...   \n",
       "1015475  i have no luck getting any support (human) to ...   \n",
       "1833772  although it didn't slip right into place like ...   \n",
       "...                                                    ...   \n",
       "1461079  not sure how i've been teaching for 4 years wi...   \n",
       "1603521  like it alot, holds up well on the outside of ...   \n",
       "1232082  very happy with the bubble wrap and speedy del...   \n",
       "2582464  i had no problems at all with this printer.  a...   \n",
       "1361289  the time had come for a new standard home phon...   \n",
       "\n",
       "                                         without_html_urls  \\\n",
       "525783   feeble and fragile ... good design idea... inf...   \n",
       "880086   years ago we had an hp printer that created al...   \n",
       "2208773  in less than one month of use, the yellow tone...   \n",
       "1015475  i have no luck getting any support (human) to ...   \n",
       "1833772  although it didn't slip right into place like ...   \n",
       "...                                                    ...   \n",
       "1461079  not sure how i've been teaching for 4 years wi...   \n",
       "1603521  like it alot, holds up well on the outside of ...   \n",
       "1232082  very happy with the bubble wrap and speedy del...   \n",
       "2582464  i had no problems at all with this printer.  a...   \n",
       "1361289  the time had come for a new standard home phon...   \n",
       "\n",
       "                                      without_contractions  \\\n",
       "525783   feeble and fragile ... good design idea... inf...   \n",
       "880086   years ago we had an hp printer that created al...   \n",
       "2208773  in less than one month of use, the yellow tone...   \n",
       "1015475  i have no luck getting any support (human) to ...   \n",
       "1833772  although it did not slip right into place like...   \n",
       "...                                                    ...   \n",
       "1461079  not sure how I have been teaching for 4 years ...   \n",
       "1603521  like it alot, holds up well on the outside of ...   \n",
       "1232082  very happy with the bubble wrap and speedy del...   \n",
       "2582464  i had no problems at all with this printer. af...   \n",
       "1361289  the time had come for a new standard home phon...   \n",
       "\n",
       "                                     with_alpha_chars_only  \\\n",
       "525783   feeble and fragile     good design idea    inf...   \n",
       "880086   years ago we had an hp printer that created al...   \n",
       "2208773  in less than one month of use  the yellow tone...   \n",
       "1015475  i have no luck getting any support  human  to ...   \n",
       "1833772  although it did not slip right into place like...   \n",
       "...                                                    ...   \n",
       "1461079  not sure how I have been teaching for   years ...   \n",
       "1603521  like it alot  holds up well on the outside of ...   \n",
       "1232082  very happy with the bubble wrap and speedy del...   \n",
       "2582464  i had no problems at all with this printer  af...   \n",
       "1361289  the time had come for a new standard home phon...   \n",
       "\n",
       "                                       without_extra_space  \\\n",
       "525783   feeble and fragile good design idea inferior j...   \n",
       "880086   years ago we had an hp printer that created al...   \n",
       "2208773  in less than one month of use the yellow toner...   \n",
       "1015475  i have no luck getting any support human to he...   \n",
       "1833772  although it did not slip right into place like...   \n",
       "...                                                    ...   \n",
       "1461079  not sure how I have been teaching for years wi...   \n",
       "1603521  like it alot holds up well on the outside of y...   \n",
       "1232082  very happy with the bubble wrap and speedy del...   \n",
       "2582464  i had no problems at all with this printer aft...   \n",
       "1361289  the time had come for a new standard home phon...   \n",
       "\n",
       "                                        without_stop_words  \\\n",
       "525783   feeble fragile good design idea inferior joint...   \n",
       "880086   years ago hp printer created kinds havoc windo...   \n",
       "2208773  less one month use yellow toner exploded insid...   \n",
       "1015475  luck getting support human help setting thing ...   \n",
       "1833772  although slip right place like old one fit pro...   \n",
       "...                                                    ...   \n",
       "1461079  sure I teaching years without one even redicul...   \n",
       "1603521  like alot holds well outside door small packag...   \n",
       "1232082                  happy bubble wrap speedy delivery   \n",
       "2582464  problems printer receiving problems setting in...   \n",
       "1361289  time come new standard home phone fit requirem...   \n",
       "\n",
       "                                            lemmed_reviews  \n",
       "525783   feeble fragile good design idea inferior joint...  \n",
       "880086   year ago hp printer created kind havoc window ...  \n",
       "2208773  le one month use yellow toner exploded inside ...  \n",
       "1015475  luck getting support human help setting thing ...  \n",
       "1833772  although slip right place like old one fit pro...  \n",
       "...                                                    ...  \n",
       "1461079  sure I teaching year without one even rediculo...  \n",
       "1603521  like alot hold well outside door small package...  \n",
       "1232082                  happy bubble wrap speedy delivery  \n",
       "2582464  problem printer receiving problem setting inst...  \n",
       "1361289  time come new standard home phone fit requirem...  \n",
       "\n",
       "[1500 rows x 14 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, review_class):\n",
    "    embeddings_df = df.dropna(subset=[review_class])\n",
    "    print(len(embeddings_df), embeddings_df['star_rating'].unique())\n",
    "\n",
    "    specific_review_class = embeddings_df[review_class]\n",
    "    print(specific_review_class.unique())\n",
    "\n",
    "    text = embeddings_df.loc[:, ['lemmed_reviews']]\n",
    "    print(text)\n",
    "\n",
    "    ### Train test split so I can have the same train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(text, specific_review_class, test_size=0.2, random_state=42)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary\n",
      "\n",
      "1200 [1 2 4 5]\n",
      "[2. 1.]\n",
      "                                            lemmed_reviews\n",
      "525783   feeble fragile good design idea inferior joint...\n",
      "880086   year ago hp printer created kind havoc window ...\n",
      "2208773  le one month use yellow toner exploded inside ...\n",
      "1015475  luck getting support human help setting thing ...\n",
      "1833772  although slip right place like old one fit pro...\n",
      "...                                                    ...\n",
      "1461079  sure I teaching year without one even rediculo...\n",
      "1603521  like alot hold well outside door small package...\n",
      "1232082                  happy bubble wrap speedy delivery\n",
      "2582464  problem printer receiving problem setting inst...\n",
      "1361289  time come new standard home phone fit requirem...\n",
      "\n",
      "[1200 rows x 1 columns]\n",
      "(960, 1) (240, 1) (960,) (240,)\n",
      "\n",
      "Ternary\n",
      "1500 [1 2 3 4 5]\n",
      "[2. 3. 1.]\n",
      "                                            lemmed_reviews\n",
      "525783   feeble fragile good design idea inferior joint...\n",
      "880086   year ago hp printer created kind havoc window ...\n",
      "2208773  le one month use yellow toner exploded inside ...\n",
      "1015475  luck getting support human help setting thing ...\n",
      "1833772  although slip right place like old one fit pro...\n",
      "...                                                    ...\n",
      "1461079  sure I teaching year without one even rediculo...\n",
      "1603521  like alot hold well outside door small package...\n",
      "1232082                  happy bubble wrap speedy delivery\n",
      "2582464  problem printer receiving problem setting inst...\n",
      "1361289  time come new standard home phone fit requirem...\n",
      "\n",
      "[1500 rows x 1 columns]\n",
      "(1200, 1) (300, 1) (1200,) (300,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary\\n\")\n",
    "binary_X_train, binary_X_test, binary_y_train, binary_y_test = split_data(cleaned_reviews_df, 'binary_review_class')\n",
    "print(\"\\nTernary\")\n",
    "ternary_X_train, ternary_X_test, ternary_y_train, ternary_y_test = split_data(cleaned_reviews_df, 'ternary_review_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model and train my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:35:54,880 : INFO : loading projection weights from /Users/brinkley97/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2024-02-07 19:36:32,131 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/brinkley97/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-02-07T19:36:32.131496', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import gensim.downloader as api\n",
    "pretrained_word_two_vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:36:32,176 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-02-07 19:36:32,177 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2024-02-07 19:36:32,178 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2024-02-07T19:36:32.178237', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, col_name: str):\n",
    "        self.df = df\n",
    "        self.col_name = col_name\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: `pd.DataFrame`\n",
    "            The data\n",
    "        \n",
    "        col_name: `str`\n",
    "            Column with reviews\n",
    "\n",
    "        words_in_model: `list`\n",
    "            Words in Word2Vec model\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        text_reviews = self.df[self.col_name].values\n",
    "\n",
    "        for text_reviews_idx in range(len(text_reviews)):\n",
    "            text_review = text_reviews[text_reviews_idx]\n",
    "            # print(text_reviews_idx, \"--\", text_review)\n",
    "\n",
    "            yield utils.simple_preprocess(text_review)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:36:32,268 : INFO : collecting all words and their counts\n",
      "2024-02-07 19:36:32,269 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-02-07 19:36:32,309 : INFO : collected 4553 word types from a corpus of 27418 raw words and 960 sentences\n",
      "2024-02-07 19:36:32,309 : INFO : Creating a fresh vocabulary\n",
      "2024-02-07 19:36:32,312 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 577 unique words (12.67% of original 4553, drops 3976)', 'datetime': '2024-02-07T19:36:32.312229', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,312 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 18480 word corpus (67.40% of original 27418, drops 8938)', 'datetime': '2024-02-07T19:36:32.312962', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,315 : INFO : deleting the raw counts dictionary of 4553 items\n",
      "2024-02-07 19:36:32,316 : INFO : sample=0.001 downsamples 87 most-common words\n",
      "2024-02-07 19:36:32,316 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 15100.44592133145 word corpus (81.7%% of prior 18480)', 'datetime': '2024-02-07T19:36:32.316823', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,322 : INFO : estimated required memory for 577 words and 300 dimensions: 1673300 bytes\n",
      "2024-02-07 19:36:32,322 : INFO : resetting layer weights\n",
      "2024-02-07 19:36:32,324 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-02-07T19:36:32.324339', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2024-02-07 19:36:32,325 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 577 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=11 shrink_windows=True', 'datetime': '2024-02-07T19:36:32.325051', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-02-07 19:36:32,375 : INFO : EPOCH 0: training on 27418 raw words (15107 effective words) took 0.0s, 391804 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:36:32,646 : INFO : EPOCH 1: training on 27418 raw words (15060 effective words) took 0.3s, 57163 effective words/s\n",
      "2024-02-07 19:36:32,711 : INFO : EPOCH 2: training on 27418 raw words (15149 effective words) took 0.1s, 258254 effective words/s\n",
      "2024-02-07 19:36:32,772 : INFO : EPOCH 3: training on 27418 raw words (15087 effective words) took 0.1s, 284447 effective words/s\n",
      "2024-02-07 19:36:32,823 : INFO : EPOCH 4: training on 27418 raw words (15178 effective words) took 0.0s, 353232 effective words/s\n",
      "2024-02-07 19:36:32,823 : INFO : Word2Vec lifecycle event {'msg': 'training on 137090 raw words (75581 effective words) took 0.5s, 151728 effective words/s', 'datetime': '2024-02-07T19:36:32.823837', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-02-07 19:36:32,824 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=577, vector_size=300, alpha=0.025>', 'datetime': '2024-02-07T19:36:32.824312', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'created'}\n",
      "2024-02-07 19:36:32,825 : INFO : collecting all words and their counts\n",
      "2024-02-07 19:36:32,826 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-02-07 19:36:32,874 : INFO : collected 5067 word types from a corpus of 33838 raw words and 1200 sentences\n",
      "2024-02-07 19:36:32,875 : INFO : Creating a fresh vocabulary\n",
      "2024-02-07 19:36:32,877 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 694 unique words (13.70% of original 5067, drops 4373)', 'datetime': '2024-02-07T19:36:32.877888', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,878 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 23890 word corpus (70.60% of original 33838, drops 9948)', 'datetime': '2024-02-07T19:36:32.878462', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,881 : INFO : deleting the raw counts dictionary of 5067 items\n",
      "2024-02-07 19:36:32,882 : INFO : sample=0.001 downsamples 85 most-common words\n",
      "2024-02-07 19:36:32,882 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 20028.149067907554 word corpus (83.8%% of prior 23890)', 'datetime': '2024-02-07T19:36:32.882672', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-07 19:36:32,887 : INFO : estimated required memory for 694 words and 300 dimensions: 2012600 bytes\n",
      "2024-02-07 19:36:32,888 : INFO : resetting layer weights\n",
      "2024-02-07 19:36:32,890 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-02-07T19:36:32.890037', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2024-02-07 19:36:32,890 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 694 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=11 shrink_windows=True', 'datetime': '2024-02-07T19:36:32.890666', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-02-07 19:36:32,951 : INFO : EPOCH 0: training on 33838 raw words (20056 effective words) took 0.0s, 409788 effective words/s\n",
      "2024-02-07 19:36:33,016 : INFO : EPOCH 1: training on 33838 raw words (20035 effective words) took 0.1s, 346112 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ternary Case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:36:33,079 : INFO : EPOCH 2: training on 33838 raw words (20043 effective words) took 0.1s, 359382 effective words/s\n",
      "2024-02-07 19:36:33,140 : INFO : EPOCH 3: training on 33838 raw words (20025 effective words) took 0.1s, 374098 effective words/s\n",
      "2024-02-07 19:36:33,203 : INFO : EPOCH 4: training on 33838 raw words (20030 effective words) took 0.1s, 362047 effective words/s\n",
      "2024-02-07 19:36:33,204 : INFO : Word2Vec lifecycle event {'msg': 'training on 169190 raw words (100189 effective words) took 0.3s, 319608 effective words/s', 'datetime': '2024-02-07T19:36:33.204614', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-02-07 19:36:33,205 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=694, vector_size=300, alpha=0.025>', 'datetime': '2024-02-07T19:36:33.205121', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Case\")\n",
    "binary_X_train_sentences = MyCorpus(binary_X_train, 'lemmed_reviews')\n",
    "my_binary_X_train_model = gensim.models.Word2Vec(sentences=binary_X_train_sentences, vector_size=300, window=11, min_count=10)\n",
    "\n",
    "# X test - get embeddings from my_binary_X_train_model -- vec_king = my_binary_X_train_model.wv['king']\n",
    "# binary_X_test_sentences = MyCorpus(binary_X_test, 'lemmed_reviews')\n",
    "# sentences = MyCorpus(sampled_reviews_ratings_df, 'review_body')\n",
    "# print(\"\\nSentences\", binary_X_test_sentences)\n",
    "\n",
    "print(\"\\nTernary Case\")\n",
    "ternary_X_train_sentences = MyCorpus(ternary_X_train, 'lemmed_reviews')\n",
    "my_ternary_X_train_model = gensim.models.Word2Vec(sentences=ternary_X_train_sentences, vector_size=300, window=11, min_count=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar scores\n",
    "\n",
    "[ ] Write summary of differences between their model and my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519)]\n"
     ]
    }
   ],
   "source": [
    "result = pretrained_word_two_vec_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1078da750>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_trained_binary_X_train_model = my_binary_X_train_model.wv\n",
    "my_trained_binary_X_train_model\n",
    "\n",
    "my_trained_ternary_X_train_model = my_ternary_X_train_model.wv\n",
    "my_trained_ternary_X_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jammed', 0.007604660931974649), ('level', 0.007585110608488321), ('cord', 0.00752635532990098), ('exactly', 0.006755036301910877), ('add', 0.006493216380476952), ('useful', 0.006399194709956646), ('dollar', 0.006285232026129961), ('easier', 0.006052954122424126), ('drop', 0.005979087669402361), ('smooth', 0.005930942017585039)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix with proper exs\n",
    "my_result = my_trained_binary_X_train_model.most_similar(positive=['started', 'even'], negative=['plus', 'toner'], topn=10)\n",
    "print(my_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(df: pd.DataFrame, col_name: str, model_to_use):\n",
    "    \"\"\"Extract word embeddings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    model_to_use:\n",
    "        Either the pretrained model or my pretrained model\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    sentence_vectorized = []\n",
    "    mean_sentences_vectorized = []\n",
    "    sentences = df[col_name].values\n",
    "\n",
    "    for sentences_idx in range(len(sentences)):\n",
    "        vectorized_words = []\n",
    "        sentence = sentences[sentences_idx]\n",
    "        # print(\"Sentence\", sentences_idx)\n",
    "        # print(\"Sentence\", sentences_idx, \"Pre-vectorized -- \", sentence)\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word in model_to_use.key_to_index:\n",
    "                vector_of_word = model_to_use[word]\n",
    "                vectorized_words.append(vector_of_word)\n",
    "                # print(\"--->\", word, \"is in model with vector lenght of\", len(vector_of_word))\n",
    "            else:\n",
    "                vector_of_word = np.random.rand(model_to_use.vector_size)\n",
    "                vectorized_words.append(vector_of_word)\n",
    "                \n",
    "        sentence_vectorized.append(vectorized_words)\n",
    "        # print(\"Sentence\", sentences_idx, \"Post-vectorized \\n\")\n",
    "\n",
    "        mean_of_sentence = np.mean(sentence_vectorized[sentences_idx], axis=0)\n",
    "        # print(len(mean_of_sentence), mean_of_sentence)\n",
    "        mean_sentences_vectorized.append(mean_of_sentence)\n",
    "\n",
    "\n",
    "    return mean_sentences_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings for pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Pretrained Train\n",
      "Binary Pretrained Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((960, 300), (240, 300))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Binary Pretrained Train\")\n",
    "pretrained_binary_train_embeddings = word_embeddings(binary_X_train, 'lemmed_reviews', pretrained_word_two_vec_model)\n",
    "pretrained_binary_train_embeddings = np.array(pretrained_binary_train_embeddings)\n",
    "\n",
    "print(\"Binary Pretrained Test\")\n",
    "pretrained_binary_test_embeddings = word_embeddings(binary_X_test, 'lemmed_reviews', pretrained_word_two_vec_model)\n",
    "pretrained_binary_test_embeddings = np.array(pretrained_binary_test_embeddings)\n",
    "\n",
    "pretrained_binary_train_embeddings.shape, pretrained_binary_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary Pretrained Train\n",
      "Ternary Pretrained Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1200, 300), (300, 300))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ternary Pretrained Train\")\n",
    "pretrained_ternary_train_embeddings = word_embeddings(ternary_X_train, 'lemmed_reviews', pretrained_word_two_vec_model)\n",
    "pretrained_ternary_train_embeddings = np.array(pretrained_ternary_train_embeddings)\n",
    "\n",
    "print(\"Ternary Pretrained Test\")\n",
    "pretrained_ternary_test_embeddings = word_embeddings(ternary_X_test, 'lemmed_reviews', pretrained_word_two_vec_model)\n",
    "pretrained_ternary_test_embeddings = np.array(pretrained_ternary_test_embeddings)\n",
    "\n",
    "pretrained_ternary_train_embeddings.shape, pretrained_ternary_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary My Model Train\n",
      "Binary My Model Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((960, 300), (240, 300))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Binary My Model Train\")\n",
    "my_binary_train_embeddings = word_embeddings(binary_X_train, 'lemmed_reviews', my_trained_binary_X_train_model)\n",
    "my_binary_train_embeddings = np.array(my_binary_train_embeddings)\n",
    "\n",
    "print(\"Binary My Model Test\")\n",
    "my_binary_test_embeddings = word_embeddings(binary_X_test, 'lemmed_reviews', my_trained_binary_X_train_model)\n",
    "my_binary_test_embeddings = np.array(my_binary_test_embeddings)\n",
    "\n",
    "my_binary_train_embeddings.shape, my_binary_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary My Model Train\n",
      "Ternary My Model Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1200, 300), (300, 300))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ternary My Model Train\")\n",
    "my_ternary_train_embeddings = word_embeddings(ternary_X_train, 'lemmed_reviews', my_trained_ternary_X_train_model)\n",
    "my_ternary_train_embeddings = np.array(my_ternary_train_embeddings)\n",
    "\n",
    "print(\"Ternary My Model Test\")\n",
    "my_ternary_test_embeddings = word_embeddings(ternary_X_test, 'lemmed_reviews', my_trained_ternary_X_train_model)\n",
    "my_ternary_test_embeddings = np.array(my_ternary_test_embeddings)\n",
    "\n",
    "my_ternary_train_embeddings.shape, my_ternary_test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_feature_extraction(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Extract the TF-IDF features from the reviews.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    tf_idf_features:\n",
    "        A matrix containing the TF-IDF features extracted\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_idf_features = vectorizer.fit_transform(df[col_name])\n",
    "\n",
    "    return tf_idf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_features = tf_idf_feature_extraction(lemmed_df, 'lemmed_reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(y_true, y_prediction):\n",
    "    return sklearn.metrics.accuracy_score(y_true, y_prediction)\n",
    "\n",
    "# def eval_precision(y_true, y_prediction):\n",
    "#     return sklearn.metrics.precision_score(y_true, y_prediction)\n",
    "\n",
    "# def eval_recall(y_true, y_prediction):\n",
    "#     return sklearn.metrics.recall_score(y_true, y_prediction)\n",
    "\n",
    "# def eval_f1_score(y_true, y_prediction):\n",
    "#     return sklearn.metrics.f1_score(y_true, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_metric(y_train_true, y_train_predictions):\n",
    "    accuracy = eval_accuracy(y_train_true, y_train_predictions)\n",
    "    # precision = eval_precision(y_train_true, y_train_predictions)\n",
    "    # recall = eval_recall(y_train_true, y_train_predictions)\n",
    "    # f1 = eval_f1_score(y_train_true, y_train_predictions)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'Accuracy': accuracy,\n",
    "        # 'Precision': precision,\n",
    "        # 'Recall': recall,\n",
    "        # 'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "def test_eval_metric(y_test_true, y_test_predictions):\n",
    "    accuracy = eval_accuracy(y_test_true, y_test_predictions)\n",
    "    # precision = eval_precision(y_test_true, y_test_predictions)\n",
    "    # recall = eval_recall(y_test_true, y_test_predictions)\n",
    "    # f1 = eval_f1_score(y_test_true, y_test_predictions)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'Accuracy': accuracy,\n",
    "        # 'Precision': precision,\n",
    "        # 'Recall': recall,\n",
    "        # 'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy for perceptron on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = Perceptron(tol=1e-3, random_state=0)\n",
    "    technique.fit(X_train, y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 300), (240, 300), (960,), (240,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_binary_train_embeddings.shape, my_binary_test_embeddings.shape, binary_y_train.shape, binary_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model\n",
    "perceptron_train_metrics, perceptron_test_metrics = perceptron_model(pretrained_binary_train_embeddings, pretrained_binary_test_embeddings, binary_y_train, binary_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.86875}, {'Accuracy': 0.7291666666666666})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_train_metrics, perceptron_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy for perceptron on my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My model\n",
    "my_perceptron_train_metrics, my_perceptron_test_metrics = perceptron_model(my_binary_train_embeddings, my_binary_test_embeddings, binary_y_train, binary_y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.675}, {'Accuracy': 0.45416666666666666})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_perceptron_train_metrics, my_perceptron_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = LinearSVC(tol=1e-3, random_state=0)\n",
    "    technique.fit(X_train, y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy for svm on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_train_metrics, svm_test_metrics = svm_model(pretrained_binary_train_embeddings, pretrained_binary_test_embeddings, binary_y_train, binary_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.8645833333333334}, {'Accuracy': 0.7416666666666667})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_metrics, svm_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy for svm on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_svm_train_metrics, my_svm_test_metrics = svm_model(my_binary_train_embeddings, my_binary_test_embeddings, binary_y_train, binary_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.7333333333333333}, {'Accuracy': 0.5416666666666666})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm_train_metrics, my_svm_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I conclude from comparing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network\n",
    "- MLP for sentiment analysis classification\n",
    "- 2 hidden layers each with 50 and 10 nodes, respectively\n",
    "- Cross entropy loss\n",
    "- I decide other hyperparameters (ie: nonlinearity, #epochs, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_review_class = binary_embeddings_df['binary_review_class']\n",
    "# binary_review_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Define the NN architecture\"\"\"\n",
    "\n",
    "    def __init__(self, num_h1_nodes: int, num_h2_nodes: int, d: int, num_output_classes: int, dropout_rate: float):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # self.height = heightght = height\n",
    "        # self.width = width\n",
    "        # linear layer (1200 x 300 dot 300 x 50 -> 1200 x 50)\n",
    "        self.fc1 = nn.Linear(d, num_h1_nodes)\n",
    "        # linear layer (1200 x 50 dot 50 x 10 -> 1200 x 10)\n",
    "        self.fc2 = nn.Linear(num_h1_nodes, num_h2_nodes)\n",
    "        # linear layer (1200 x 50 dot 50 x 10 -> 1200 x 10)\n",
    "        self.fc3 = nn.Linear(num_h2_nodes, num_output_classes) # change to 3 for ternery\n",
    "        # dropout to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add hidden layer, with relu activation function, dropout, relu, dropout, output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def train_network(self, number_of_epochs: int, optimizer, criterion_function, train_loader):\n",
    "        # set initial \"min\" to infinity\n",
    "        valid_loss_min = np.Inf\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "            train_loss = 0.0\n",
    "            \n",
    "\n",
    "            ###################\n",
    "            # train the model #\n",
    "            ###################\n",
    "            self.train() # prep model for training\n",
    "            for data, target in train_loader:\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass to compute predictions, loss, backward pass to compute gradient wrt model params\n",
    "                output = self(data)\n",
    "                loss = criterion_function(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # update running training loss\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            # print training statistics \n",
    "            # calculate average loss over an epoch\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            \n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "                epoch+1, \n",
    "                train_loss,\n",
    "                ))\n",
    "            \n",
    "            # # save model if validation loss has decreased\n",
    "            # if train_loss <= valid_loss_min:\n",
    "            #     print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            #     valid_loss_min,\n",
    "            #     train_loss))\n",
    "            #     torch.save(self.state_dict(), 'nn_model.pt')\n",
    "            #     valid_loss_min = train_loss\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            outputs = self(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            ground_truth.extend(targets.cpu().numpy())\n",
    "\n",
    "        # Convert predictions and ground truth lists to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        ground_truth = np.array(ground_truth)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = (predictions == ground_truth).mean()\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_binary_embeddings, d_binary_embeddings = my_binary_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_h1_nodes = 50\n",
    "num_h2_nodes = 10\n",
    "num_output_classes = 2\n",
    "dropout_rate = 0.2\n",
    "\n",
    "net_model = Net(num_h1_nodes, num_h2_nodes, d_binary_embeddings, num_output_classes, dropout_rate)\n",
    "print(net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_model(binary_train_embeddings, binary_train_y):\n",
    "    binary_train_y = binary_train_y.replace(2, 0)\n",
    "    data_tensor = torch.tensor(binary_train_embeddings, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(binary_train_y.values, dtype=torch.long)\n",
    "    dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "    # how many samples per batch to load\n",
    "    batch_size = 64\n",
    "\n",
    "    # as a positive integer will turn on multi-process data loading with the specified number of loader worker processes; otherwise, single-process data loading\n",
    "    num_workers = 0\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    number_of_epochs = 3\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net_model.parameters(), lr=0.01)\n",
    "    output_of_model = net_model.train_network(number_of_epochs, optimizer, criterion, train_loader)\n",
    "    \n",
    "    return output_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391287    2.0\n",
       "237246     2.0\n",
       "832872     2.0\n",
       "1691509    1.0\n",
       "2257654    2.0\n",
       "          ... \n",
       "693447     1.0\n",
       "1385083    1.0\n",
       "1610920    1.0\n",
       "1978013    1.0\n",
       "2254291    1.0\n",
       "Name: binary_review_class, Length: 960, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.707500\n",
      "Epoch: 2 \tTraining Loss: 0.705389\n",
      "Epoch: 3 \tTraining Loss: 0.703271\n"
     ]
    }
   ],
   "source": [
    "train_binary_model(pretrained_binary_train_embeddings, binary_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.700519\n",
      "Epoch: 2 \tTraining Loss: 0.700768\n",
      "Epoch: 3 \tTraining Loss: 0.698298\n"
     ]
    }
   ],
   "source": [
    "train_binary_model(my_binary_train_embeddings, binary_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_binary_model(binary_test_embeddings, binary_test_y):\n",
    "    binary_test_y = binary_test_y.replace(2, 0)\n",
    "    target_array = binary_test_y.values\n",
    "    data_tensor = torch.tensor(binary_test_embeddings, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # Create a PyTorch tensor from the NumPy array\n",
    "    target_tensor = torch.tensor(target_array, dtype=torch.long)  # Assuming target is of type long/int\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 1\n",
    "\n",
    "    # Define number of DataLoader workers\n",
    "    num_workers = 0  # Set this to a positive integer to enable multi-process data loading\n",
    "\n",
    "    # Create DataLoader\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    # Assuming net_model is an instance of your model\n",
    "    predictions = net_model.predict(test_loader)\n",
    "    # predictions = np.array(predictions)\n",
    "    # predictions_flat = predictions.flatten()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49166666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49166666666666664"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_binary_model(pretrained_binary_test_embeddings, binary_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ternary_embeddings, d_ternary_embeddings = my_ternary_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_h1_nodes = 50\n",
    "num_h2_nodes = 10\n",
    "num_output_classes = 3\n",
    "dropout_rate = 0.2\n",
    "\n",
    "net_model = Net(num_h1_nodes, num_h2_nodes, d_binary_embeddings, num_output_classes, dropout_rate)\n",
    "print(net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ternary_model(ternary_train_embeddings, ternary_train_y):\n",
    "    ternary_train_y = ternary_train_y.replace(2, 0)\n",
    "    ternary_train_y = ternary_train_y.replace(3, 2)\n",
    "    data_tensor = torch.tensor(ternary_train_embeddings, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(ternary_train_y.values, dtype=torch.long)\n",
    "    dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "    # how many samples per batch to load\n",
    "    batch_size = 64\n",
    "\n",
    "    # as a positive integer will turn on multi-process data loading with the specified number of loader worker processes; otherwise, single-process data loading\n",
    "    num_workers = 0\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    number_of_epochs = 3\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net_model.parameters(), lr=0.01)\n",
    "    output_of_model = net_model.train_network(number_of_epochs, optimizer, criterion, train_loader)\n",
    "    \n",
    "    return output_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.071023\n",
      "Epoch: 2 \tTraining Loss: 1.069538\n",
      "Epoch: 3 \tTraining Loss: 1.068447\n"
     ]
    }
   ],
   "source": [
    "train_ternary_model(pretrained_ternary_train_embeddings, ternary_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ternary_model(ternary_test_embeddings, ternary_test_y):\n",
    "    ternary_test_y = ternary_test_y.replace(2, 0)\n",
    "    ternary_test_y = ternary_test_y.replace(3, 2)\n",
    "    target_array = ternary_test_y.values\n",
    "    data_tensor = torch.tensor(ternary_test_embeddings, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # Create a PyTorch tensor from the NumPy array\n",
    "    target_tensor = torch.tensor(target_array, dtype=torch.long)  # Assuming target is of type long/int\n",
    "\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 1\n",
    "\n",
    "    # Define number of DataLoader workers\n",
    "    num_workers = 0  # Set this to a positive integer to enable multi-process data loading\n",
    "\n",
    "    # Create DataLoader\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    # Assuming net_model is an instance of your model\n",
    "    predictions = net_model.predict(test_loader)\n",
    "    # predictions = np.array(predictions)\n",
    "    # predictions_flat = predictions.flatten()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4033333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4033333333333333"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ternary_model(pretrained_ternary_test_embeddings, ternary_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
